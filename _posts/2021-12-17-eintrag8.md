---
title: "Suchmaschinen und Discovery-Systeme (17.12.2021)"
date: 2021-12-17
---
In der heutigen Lerneinheit beenden wir das Thema **Metadaten modellieren und Schnittstellen nutzen** um anschliessend das Thema **Suchmaschinen und Discovery-Systeme** zu behandeln.

Das **Metadaten-Management** ist in der Bibliothek- und Archivbranche ein wichtiges Thema. Unterthemen sind Metadaten-Standards, Metadatenanalyse oder das Mapping. Ein Tool zur Bereinigung und Umwandlung von Daten, dass wir bereits in der letzten Einheit kennengelernt haben, ist OpenRefine. Dies ist auf Grund der grafischen Oberfläche sehr benutzerfreundlich, da man dadurch Änderungen gut nachvollziehen kann. Zudem hat man mit Skriptsprachen die Möglichkeit auch komplexere Transformationen umzusetzen. Alternative Software in der Praxis wären [Catmandu](https://librecat.org/), [Metafacture](https://github.com/metafacture/metafacture-core) und [MarcEdit](https://marcedit.reeset.net/). Ich kenne keine davon, ich habe aber schon mit [Mp3tag](https://www.mp3tag.de/), einer Software zur Bearbeitung von Metadaten in Audioformaten gearbeitet, als ich CDs digitalisiert habe. Dies hat mich stark an OpenRefine erinnert, da diese Software ebenfalls eine grafische Oberfläche hat, die Abfrage von Online-Datenbanken möglich ist und man mit Skripten arbeiten kann.

Bisher haben wir im Kurs bei allen Schnittstellen, die wir abgefragt haben mit XML gearbeitet. Dies ist im Bibliothek- und Archivumfeld nach wie das mit Abstand verbreitetste Austauschformat. Aber gerade im Webkontext hat es einen Wechsel gegeben weg von XML zu JSON. Darum wird in einem kleinen Exkurs die **Nutzung von JSON-APIs** behandelt. JSON ist ebenfalls ein strukturiertes Format wie XML, aber einfacher gehalten. So gibt es keine Attribute oder nach Schema definierte Namen wie in XML. Dadurch und weil es mit JavaScript (woher es stammt) sehr effizient verarbeitet wird, ist JSON sehr beliebt im Webkontext. Im Bibliothekskontext gibt es beispielsweise die JSON API [lobid-gnd API](https://lobid.org/gnd/api) von der Gemeinsamen Normdatei der Deutschen Nationalbibliothek. Interessant ist das Tool [scrAPIr](https://scrapir.org/), es gibt eine Übersicht über die APIs verschiedener bekannten Webseiten und Hilfe zu deren Abfrage, die meisten APIs davon sind in JSON.



Im zweiten Teil der Lerneinheit geht es um das Thema**Suchmaschinen und Discovery-Systeme**.
Als Vorbereitung auf dieses Thema haben wir auf unserer virtuellen Umgebung [VuFind](https://vufind.org/vufind/) installiert. Ich hatte wieder einmal «Glück», auch diese Installation hat bei mir ohne Probleme funktioniert. **VuFind** ist eine weltweit verbreitete Opensource Software, mit der Bibliothekskataloge betrieben werden können, also ein Discovery-System. Ein Vorteil von VuFind ist, dass es sehr gut angepasst und so zu einem individuellen Katalog gemacht werden kann.
Die Suchmaschine, die VuFind zu Grund liegt heisst **Solr**. Solr ist zusammen mit Elasticsearch Industriestandard, beide funktionieren sehr ähnlich und sind Opensource.  Vor dem Import der Daten sollte in einem Schema festgelegt werden, welche Felder existieren und welche Datentypen diese beinhalten dürfen, um eine gute Effizienz zu erreichen. Die eigentliche Web- bzw. Benutzungsoberfläche um die Suche herum ist dann das Discovery-System, in unserem Fall VuFind. Im Unterschied zu einer Datenbank (z.B. MySQL), bei der das Ziel eher das Verwalten und Aufbewahren ist, steht bei einem Suchindex wie Solr das Auffinden im Zentrum. Ein Suchindex zeichnet sich entsprechend durch flache Dokumente, lexikalische Suche, keiner Konsistenzprüfung und statistischen Daten aus. Solr in VuFind bietet eine Administrationsoberfläche. Dort kann beispielsweise das Schema bearbeitet werden oder man kann mit der Funktion Query Beispielabfragen machen.

In einer ersten Übung ging es darum dieselbe **Suche in VuFind und in Solr** zu machen und Unterschiede bzw. Auffälligkeiten zu notieren. Der Hauptunterschied ist, dass man in Solr einfach eine reine Datenansicht hat, während im VuFind die Ergebnisse für die Benutzenden aufbereitet sind. Parallel haben wir uns die Logdateien angeschaut, hierbei fiel auf, dass bei der VuFind im Code Felder und Zahlen zu sehen waren. Diese stellen das Relevance Ranking dar, welches in VuFind auch konfiguriert werden kann.

Abschliessend haben wir eine **Übung zur Datenintegration** gemacht. Das Ziel dabei ist der Import der in der letzten Einheit mit MarcEdit und OpenRefine konvertierten Daten aus Koha, ArchivesSpace, DSpace und DOAJ in VuFind. Also ein übergreifender Katalog für unsere Daten. Der Import hat bei vielen Daten gut funktioniert, der Import von gewissen Daten ging aber wie bereits in der Aufgabenstellung angekündigt nicht. Das Terminal meldet, dass der Import fehlschlägt, weil die ID null sei. VuFind braucht für jeden Datensatz eine eindeutige ID.

Mit der heutigen Lerneinheit und der abschliessenden Übung haben wir das ganze Schaubild (Quelle: «Gemeinsames Dokument» des Moduls) abgedeckt. Wir haben aus den vier Quellen Koha, ArchivesSpace, DSpace und DOAJ Daten über die aufgezeigten Schnittstellen und Konvertierungen im DiscoverySystem VuFind zusammengeführt (von links nach rechts). 
![schaubild](https://user-images.githubusercontent.com/80347185/133646756-9aa33341-eb40-46ab-b489-fe8a812598b5.png)
